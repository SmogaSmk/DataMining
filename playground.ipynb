{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "133c1677",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9b9f27",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638191a6",
   "metadata": {},
   "source": [
    "examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "165be4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b0a4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_pipeline.pipeline import MLPipeline_NP\n",
    "from ML_pipeline.models import KNN \n",
    "import pandas as pd \n",
    "X_train = pd.read_csv('data/nyc_train.csv')[:12000]\n",
    "y_train = X_train.pop('dropoff_BoroCode')\n",
    "X_train = X_train[['pickup_longitude', 'pickup_latitude']]\n",
    "X_test = pd.read_csv('data/nyc_train.csv')[12000:16000]\n",
    "y_test = X_test.pop('dropoff_BoroCode')\n",
    "X_test = X_test[['pickup_longitude', 'pickup_latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b3eb5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "26858dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 5\n",
      "[1 1 1 ... 1 1 1]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "model = KNN(k=4)\n",
    "pipeline = MLPipeline_NP(model)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "preds = pipeline.predict(X_test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b878844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "值 1: 出现 3951 次\n",
      "值 3: 出现 29 次\n",
      "值 4: 出现 19 次\n",
      "值 5: 出现 1 次\n"
     ]
    }
   ],
   "source": [
    "# 返回唯一值和对应的计数\n",
    "unique_values, counts = np.unique(preds, return_counts=True)\n",
    "\n",
    "# 打印结果\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"值 {value}: 出现 {count} 次\")\n",
    "    \n",
    "from ML_pipeline.utils.evaluate import ModelEvaluator\n",
    "accuracy = ModelEvaluator.accuracy(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aa442289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "值 1: 出现 3469 次\n",
      "值 2: 出现 18 次\n",
      "值 3: 出现 377 次\n",
      "值 4: 出现 134 次\n",
      "值 5: 出现 2 次\n"
     ]
    }
   ],
   "source": [
    "# 返回唯一值和对应的计数\n",
    "unique_values, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "# 打印结果\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"值 {value}: 出现 {count} 次\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e446644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.075\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6945631d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "406ac5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# 重新加载模块并测试修复\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e06183b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_pipeline.pipeline import MLPipeline_NP\n",
    "from ML_pipeline.models import KNN \n",
    "from ML_pipeline.utils.evaluate import ModelEvaluator\n",
    "import pandas as pd \n",
    "X_train = pd.read_csv('data/nyc_train.csv')[:20000]\n",
    "y_train = X_train.pop('dropoff_BoroCode')\n",
    "X_train = X_train[['pickup_longitude', 'pickup_latitude']]\n",
    "X_test = pd.read_csv('data/nyc_train.csv')[20000:25000]\n",
    "y_test = X_test.pop('dropoff_BoroCode')\n",
    "X_test = X_test[['pickup_longitude', 'pickup_latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e8c327de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "标签分布:\n",
      "  标签 1: 36373 个样本\n",
      "  标签 2: 110 个样本\n",
      "  标签 3: 1596 个样本\n",
      "  标签 4: 1914 个样本\n",
      "  标签 5: 7 个样本\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"\\n标签分布:\")\n",
    "for label, count in zip(unique, counts):\n",
    "  print(f\"  标签 {label}: {count} 个样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ddbdc71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练线性分类器...\n",
      "Pipeline device: cpu\n",
      "Model device: cpu\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 训练线性分类器\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m训练线性分类器...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m train_losses, val_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 预测和评估\u001b[39;00m\n\u001b[0;32m     25\u001b[0m preds_linear \u001b[38;5;241m=\u001b[39m linear_pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32md:\\Projects\\DataMining\\Hw01\\ML_pipeline\\pipeline.py:254\u001b[0m, in \u001b[0;36mMLPipeline_P.fit\u001b[1;34m(self, X, y, epochs, batch_size, categorical_columns, validation, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 254\u001b[0m X_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mcategorical_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m y_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_target(y, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_tensor device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_tensor\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Projects\\DataMining\\Hw01\\ML_pipeline\\pipeline.py:227\u001b[0m, in \u001b[0;36mMLPipeline_P.preprocess_features\u001b[1;34m(self, X, is_training, categorical_columns)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[0;32m    222\u001b[0m       result_data, _ \u001b[38;5;241m=\u001b[39m scale_features(\n\u001b[0;32m    223\u001b[0m         result_data, numeric_columns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_type, \n\u001b[0;32m    224\u001b[0m         fit_scaler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_scaler\n\u001b[0;32m    225\u001b[0m       )\n\u001b[1;32m--> 227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\DataMining\\Hw01\\ML_pipeline\\utils\\tensor_convert.py:25\u001b[0m, in \u001b[0;36mTensorConverter.to_tensor\u001b[1;34m(data, device)\u001b[0m\n\u001b[0;32m     23\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "source": [
    "# 直接使用现有pipeline测试线性分类器\n",
    "from ML_pipeline.pipeline import MLPipeline_P\n",
    "from ML_pipeline.models.LearningNetworks import LinearMultiClassification\n",
    "import numpy as np\n",
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = ''\n",
    "\n",
    "# 创建线性分类器\n",
    "input_size = X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "linear_model = LinearMultiClassification(input_size=input_size, output_size=num_classes)\n",
    "linear_pipeline = MLPipeline_P(model=linear_model, scaler_type='standard', device='cpu')\n",
    "\n",
    "# 训练线性分类器\n",
    "print(\"训练线性分类器...\")\n",
    "train_losses, val_accuracies = linear_pipeline.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation=(X_test, y_test)\n",
    ")\n",
    "\n",
    "# 预测和评估\n",
    "preds_linear = linear_pipeline.predict(X_test)\n",
    "accuracy_linear = ModelEvaluator.accuracy(preds_linear, y_test)\n",
    "\n",
    "print(f\"线性分类器准确率: {accuracy_linear:.4f}\")\n",
    "print(f\"最佳验证准确率: {max(val_accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5d87b7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 模型对比 ===\n",
      "KNN准确率: 86.0750\n",
      "线性分类器准确率: 93.2000\n",
      "性能提升: 7.1250 (8.3%)\n"
     ]
    }
   ],
   "source": [
    "# 对比线性分类器和KNN\n",
    "print(\"=== 模型对比 ===\")\n",
    "print(f\"KNN准确率: {accuracy:.4f}\")\n",
    "print(f\"线性分类器准确率: {accuracy_linear:.4f}\")\n",
    "\n",
    "# 性能提升\n",
    "improvement = accuracy_linear - accuracy\n",
    "print(f\"性能提升: {improvement:.4f} ({improvement/accuracy*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c7fd3a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/nyc_train.csv')[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5b7fd511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vendor_id', 'pickup_datetime', 'dropoff_datetime', 'passenger_count',\n",
       "       'trip_distance', 'pickup_longitude', 'pickup_latitude', 'rate_code',\n",
       "       'store_and_fwd_flag', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'payment_type', 'fare_amount', 'surcharge', 'mta_tax', 'tip_amount',\n",
       "       'tolls_amount', 'total_amount', 'pickup_BoroCode', 'pickup_NTACode',\n",
       "       'dropoff_BoroCode', 'dropoff_NTACode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a95221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_pipeline.pipeline import MLPipeline_NP\n",
    "from ML_pipeline.models import KNN \n",
    "from ML_pipeline.utils.evaluate import ModelEvaluator\n",
    "import pandas as pd \n",
    "X_train = pd.read_csv('data/nyc_train.csv')[:20000]\n",
    "y_train = X_train.pop('dropoff_BoroCode')\n",
    "X_train = X_train[['pickup_datetime', 'dropoff_datetime', 'pickup_NTACode']]\n",
    "X_test = pd.read_csv('data/nyc_train.csv')[20000:25000]\n",
    "y_test = X_test.pop('dropoff_BoroCode')\n",
    "X_test = X_test[['pickup_datetime', 'dropoff_datetime', 'pickup_NTACode']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "64a5546e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2014/10/1 0:00\n",
       "1         2014/10/1 0:00\n",
       "2         2014/10/1 0:00\n",
       "3         2014/10/1 0:00\n",
       "4         2014/10/1 0:00\n",
       "              ...       \n",
       "19995    2014/10/2 10:22\n",
       "19996    2014/10/2 10:22\n",
       "19997    2014/10/2 10:22\n",
       "19998    2014/10/2 10:22\n",
       "19999    2014/10/2 10:22\n",
       "Name: pickup_datetime, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['pickup_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "854cbeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_pipeline.utils.data_utils import extract_datetime_features\n",
    "X_train = extract_datetime_features(X_train, 'pickup_datetime')\n",
    "X_train = extract_datetime_features(X_train, 'dropoff_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6acce4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d257888",
   "metadata": {},
   "source": [
    "# 简单的字符型变量分类示例\n",
    "\n",
    "下面创建一个简单的示例，包含字符型变量的分类任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dab7ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 简单数据集概览 ===\n",
      "  education city_type  age  experience salary_level\n",
      "0        本科      三线城市   31           0           低薪\n",
      "1        硕士      一线城市   38           2           高薪\n",
      "2        高中      一线城市   41          12           中薪\n",
      "3        本科      三线城市   45          13           中薪\n",
      "4        本科      一线城市   26           7           中薪\n",
      "5        硕士      三线城市   27          13           中薪\n",
      "6        高中      二线城市   23           1           低薪\n",
      "7        高中      一线城市   34           3           低薪\n",
      "8        本科      二线城市   32           1           中薪\n",
      "9        大专      三线城市   44          13           中薪\n",
      "\n",
      "数据集形状: (500, 5)\n",
      "\n",
      "各列数据类型:\n",
      "education       object\n",
      "city_type       object\n",
      "age              int32\n",
      "experience       int32\n",
      "salary_level    object\n",
      "dtype: object\n",
      "\n",
      "目标变量分布:\n",
      "salary_level\n",
      "中薪    304\n",
      "低薪    114\n",
      "高薪     82\n",
      "Name: count, dtype: int64\n",
      "\n",
      "字符型特征分布:\n",
      "\n",
      "学历分布:\n",
      "education\n",
      "硕士    148\n",
      "本科    122\n",
      "高中    122\n",
      "大专    108\n",
      "Name: count, dtype: int64\n",
      "\n",
      "城市类型分布:\n",
      "city_type\n",
      "一线城市    186\n",
      "二线城市    166\n",
      "三线城市    148\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 创建一个简单的包含字符型变量的数据集\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ML_pipeline.pipeline import MLPipeline_P\n",
    "from ML_pipeline.models.LearningNetworks import LinearMultiClassification\n",
    "from ML_pipeline.utils.evaluate import ModelEvaluator\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "# 创建简单的示例数据\n",
    "n_samples = 500\n",
    "\n",
    "# 字符型特征 1: 学历\n",
    "education = ['高中', '大专', '本科', '硕士']\n",
    "education_data = np.random.choice(education, n_samples)\n",
    "\n",
    "# 字符型特征 2: 城市类型\n",
    "city_type = ['一线城市', '二线城市', '三线城市']\n",
    "city_data = np.random.choice(city_type, n_samples)\n",
    "\n",
    "# 数值型特征: 年龄和工作经验\n",
    "age_data = np.random.randint(22, 55, n_samples)\n",
    "experience_data = np.random.randint(0, 15, n_samples)\n",
    "\n",
    "# 创建目标变量：薪资等级（基于教育程度和城市类型）\n",
    "salary_levels = []\n",
    "for i in range(n_samples):\n",
    "    score = 0\n",
    "    \n",
    "    # 学历加分\n",
    "    if education_data[i] == '硕士':\n",
    "        score += 3\n",
    "    elif education_data[i] == '本科':\n",
    "        score += 2\n",
    "    elif education_data[i] == '大专':\n",
    "        score += 1\n",
    "    \n",
    "    # 城市类型加分\n",
    "    if city_data[i] == '一线城市':\n",
    "        score += 2\n",
    "    elif city_data[i] == '二线城市':\n",
    "        score += 1\n",
    "    \n",
    "    # 年龄和经验加分\n",
    "    if age_data[i] > 35:\n",
    "        score += 1\n",
    "    if experience_data[i] > 5:\n",
    "        score += 1\n",
    "    \n",
    "    # 根据总分确定薪资等级\n",
    "    if score >= 6:\n",
    "        salary_levels.append('高薪')\n",
    "    elif score >= 3:\n",
    "        salary_levels.append('中薪')\n",
    "    else:\n",
    "        salary_levels.append('低薪')\n",
    "\n",
    "# 创建DataFrame\n",
    "simple_df = pd.DataFrame({\n",
    "    'education': education_data,\n",
    "    'city_type': city_data,\n",
    "    'age': age_data,\n",
    "    'experience': experience_data,\n",
    "    'salary_level': salary_levels\n",
    "})\n",
    "\n",
    "print(\"=== 简单数据集概览 ===\")\n",
    "print(simple_df.head(10))\n",
    "print(f\"\\n数据集形状: {simple_df.shape}\")\n",
    "print(f\"\\n各列数据类型:\")\n",
    "print(simple_df.dtypes)\n",
    "print(f\"\\n目标变量分布:\")\n",
    "print(simple_df['salary_level'].value_counts())\n",
    "print(f\"\\n字符型特征分布:\")\n",
    "print(\"\\n学历分布:\")\n",
    "print(simple_df['education'].value_counts())\n",
    "print(\"\\n城市类型分布:\")\n",
    "print(simple_df['city_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06403e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 数据分割结果 ===\n",
      "训练集大小: (400, 4)\n",
      "测试集大小: (100, 4)\n",
      "\n",
      "=== 训练集特征示例 ===\n",
      "  education city_type  age  experience\n",
      "0        本科      三线城市   31           0\n",
      "1        硕士      一线城市   38           2\n",
      "2        高中      一线城市   41          12\n",
      "3        本科      三线城市   45          13\n",
      "4        本科      一线城市   26           7\n",
      "\n",
      "=== 字符型特征列表 ===\n",
      "字符型特征: ['education', 'city_type']\n",
      "数值型特征: ['age', 'experience']\n"
     ]
    }
   ],
   "source": [
    "# 分割数据集\n",
    "train_size = int(0.8 * len(simple_df))\n",
    "\n",
    "# 训练集\n",
    "X_train_simple = simple_df[:train_size].drop('salary_level', axis=1)\n",
    "y_train_simple = simple_df[:train_size]['salary_level']\n",
    "\n",
    "# 测试集\n",
    "X_test_simple = simple_df[train_size:].drop('salary_level', axis=1)\n",
    "y_test_simple = simple_df[train_size:]['salary_level']\n",
    "\n",
    "print(\"=== 数据分割结果 ===\")\n",
    "print(f\"训练集大小: {X_train_simple.shape}\")\n",
    "print(f\"测试集大小: {X_test_simple.shape}\")\n",
    "\n",
    "print(f\"\\n=== 训练集特征示例 ===\")\n",
    "print(X_train_simple.head())\n",
    "\n",
    "print(f\"\\n=== 字符型特征列表 ===\")\n",
    "categorical_cols = ['education', 'city_type']\n",
    "print(f\"字符型特征: {categorical_cols}\")\n",
    "print(f\"数值型特征: ['age', 'experience']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0499ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始训练包含字符型变量的分类模型 ===\n",
      "输入特征数: 4\n",
      "目标类别数: 3\n",
      "字符型特征: ['education', 'city_type']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '低薪'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m X_train_simple \u001b[38;5;241m=\u001b[39m X_train_simple\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     33\u001b[0m X_test_simple \u001b[38;5;241m=\u001b[39m X_test_simple\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 34\u001b[0m y_train_simple \u001b[38;5;241m=\u001b[39m \u001b[43my_train_simple\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m y_test_simple \u001b[38;5;241m=\u001b[39m y_test_simple\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m开始训练...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ALIENWARE\\.conda\\envs\\deepLearning\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ALIENWARE\\.conda\\envs\\deepLearning\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ALIENWARE\\.conda\\envs\\deepLearning\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\ALIENWARE\\.conda\\envs\\deepLearning\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ALIENWARE\\.conda\\envs\\deepLearning\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ALIENWARE\\.conda\\envs\\deepLearning\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ALIENWARE\\.conda\\envs\\deepLearning\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '低薪'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 使用MLPipeline_P训练包含字符型变量的模型\n",
    "print(\"=== 开始训练包含字符型变量的分类模型 ===\")\n",
    "\n",
    "# 创建模型参数\n",
    "input_size = X_train_simple.shape[1]  # 特征数量\n",
    "num_classes = len(np.unique(y_train_simple))  # 目标类别数\n",
    "\n",
    "print(f\"输入特征数: {input_size}\")\n",
    "print(f\"目标类别数: {num_classes}\")\n",
    "print(f\"字符型特征: {categorical_cols}\")\n",
    "\n",
    "# 创建线性分类器\n",
    "simple_model = LinearMultiClassification(input_size=input_size, output_size=num_classes)\n",
    "simple_pipeline = MLPipeline_P(model=simple_model, scaler_type='standard', device='cpu')\n",
    "# 转换为DataFrame便于处理\n",
    "if not isinstance(X_train_simple, pd.DataFrame):\n",
    "    X_train_simple = pd.DataFrame(X_train_simple)\n",
    "    X_test_simple = pd.DataFrame(X_test_simple)\n",
    "\n",
    "# 处理所有字符型列\n",
    "for col in X_train_simple.columns:\n",
    "    if X_train_simple[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        # 合并训练和测试数据进行编码\n",
    "        combined = pd.concat([X_train_simple[col].astype(str), X_test_simple[col].astype(str)])\n",
    "        le.fit(combined)\n",
    "        X_train_simple[col] = le.transform(X_train_simple[col].astype(str))\n",
    "        X_test_simple[col] = le.transform(X_test_simple[col].astype(str))\n",
    "\n",
    "X_train_simple = X_train_simple.astype(np.float32)\n",
    "X_test_simple = X_test_simple.astype(np.float32)\n",
    "\\\n",
    "print(\"\\n开始训练...\")\n",
    "# 训练模型 - 关键是传入categorical_columns参数\n",
    "train_losses, val_accuracies = simple_pipeline.fit(\n",
    "    X_train_simple, y_train_simple,\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    categorical_columns=categorical_cols,  # 这是关键参数！\n",
    "    validation=(X_test_simple, y_test_simple)\n",
    ")\n",
    "\n",
    "print(\"训练完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181353ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行预测和评估\n",
    "print(\"=== 模型预测和评估 ===\")\n",
    "\n",
    "# 预测 - 也要传入categorical_columns参数\n",
    "predictions = simple_pipeline.predict(\n",
    "    X_test_simple, \n",
    "    categorical_columns=categorical_cols  # 预测时也要传入\n",
    ")\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = ModelEvaluator.accuracy(predictions, y_test_simple)\n",
    "\n",
    "print(f\"测试集准确率: {accuracy:.4f}\")\n",
    "print(f\"最佳验证准确率: {max(val_accuracies):.4f}\")\n",
    "\n",
    "# 查看标签映射\n",
    "print(f\"\\n=== 标签映射 ===\")\n",
    "label_mapping = simple_pipeline.get_label_mapping()\n",
    "for original, encoded in label_mapping.items():\n",
    "    print(f\"{original} -> {encoded}\")\n",
    "\n",
    "# 预测结果示例\n",
    "print(f\"\\n=== 预测结果示例 (前10个) ===\")\n",
    "for i in range(min(10, len(predictions))):\n",
    "    print(f\"输入: 学历={X_test_simple.iloc[i]['education']}, \"\n",
    "          f\"城市={X_test_simple.iloc[i]['city_type']}, \"\n",
    "          f\"年龄={X_test_simple.iloc[i]['age']}, \"\n",
    "          f\"经验={X_test_simple.iloc[i]['experience']} => \"\n",
    "          f\"实际: {y_test_simple.iloc[i]}, 预测: {predictions[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d631b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演示对新数据的预测\n",
    "print(\"=== 新数据预测示例 ===\")\n",
    "\n",
    "# 创建一些新的测试样本\n",
    "new_data = pd.DataFrame({\n",
    "    'education': ['本科', '硕士', '高中', '大专'],\n",
    "    'city_type': ['一线城市', '二线城市', '三线城市', '一线城市'],\n",
    "    'age': [28, 35, 22, 30],\n",
    "    'experience': [3, 8, 0, 5]\n",
    "})\n",
    "\n",
    "print(\"新数据:\")\n",
    "print(new_data)\n",
    "\n",
    "# 对新数据进行预测\n",
    "new_predictions = simple_pipeline.predict(\n",
    "    new_data, \n",
    "    categorical_columns=categorical_cols\n",
    ")\n",
    "\n",
    "print(f\"\\n预测结果:\")\n",
    "for i, pred in enumerate(new_predictions):\n",
    "    row = new_data.iloc[i]\n",
    "    print(f\"学历: {row['education']}, 城市: {row['city_type']}, \"\n",
    "          f\"年龄: {row['age']}, 经验: {row['experience']} => 预测薪资: {pred}\")\n",
    "\n",
    "# 获取预测概率\n",
    "print(f\"\\n=== 预测概率 ===\")\n",
    "proba = simple_pipeline.predict_proba(new_data, categorical_columns=categorical_cols)\n",
    "class_labels = simple_pipeline.get_class_labels()\n",
    "\n",
    "print(\"各类别预测概率:\")\n",
    "for i, row_proba in enumerate(proba):\n",
    "    print(f\"样本 {i+1}:\")\n",
    "    for j, prob in enumerate(row_proba):\n",
    "        print(f\"  {class_labels[j]}: {prob:.3f}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
